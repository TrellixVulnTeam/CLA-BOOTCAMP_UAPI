{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5349838",
   "metadata": {},
   "source": [
    "<img src=\"Logo.png\" width=\"100\" align=\"left\"/> \n",
    "\n",
    "# <center> Unit 3 Project </center>\n",
    "#  <center> First section : Data cleaning  </center>\n",
    "\n",
    "In this notebook you will be cleaning your dataset and making sure it's fully ready for modeling.\n",
    "\n",
    "The used dataset is [Hepatitis C  dataset](https://www.kaggle.com/fedesoriano/hepatitis-c-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a880ce",
   "metadata": {},
   "source": [
    "## Data preparation \n",
    "As a first step we need to prepare the data :\n",
    "\n",
    "1. Read the data set as a data frame ( file name is HepatitisCdata.csv) \n",
    "2. The here are the column of your dataset:\n",
    "    1) X (Patient ID/No.)\n",
    "    2) Category (diagnosis) (values: '0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis', '2=Fibrosis', '3=Cirrhosis') ( the target ) \n",
    "    3) Age (in years)\n",
    "    4) Sex (f,m)\n",
    "    Attributes 5 to 14 refer to laboratory data:\n",
    "    5) ALB : Albumin Blood Test\n",
    "    6) ALP : Alkaline phosphatase\n",
    "    7) ALT : Alanine Transaminase\n",
    "    8) AST : Aspartate Transaminase\n",
    "    9) BIL : Bilirubin\n",
    "    10) CHE : Acetylcholinesterase\n",
    "    11) CHOL : Cholesterol\n",
    "    12) CREA : Creatinine \n",
    "    13) GGT : Gamma-Glutamyl Transferase\n",
    "    14) PROT : Proteins\n",
    "    \n",
    "3. Remember your model only accepts numbers so make sure you deal properly with the missing values and the data types and justify your solution choices \n",
    " \n",
    "4. Make sure the dataset shape in the end is : rows 615 and  14 columns \n",
    " \n",
    "5. Once finished save the cleaned dataset as \"clean_HepatitisC.csv\" file \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef3a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75c3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To-Do: read the dataset \n",
    "data = pd.read_csv(\"HepatitisCdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "690a3bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 615 entries, 0 to 614\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  615 non-null    int64  \n",
      " 1   Category    615 non-null    object \n",
      " 2   Age         615 non-null    int64  \n",
      " 3   Sex         615 non-null    object \n",
      " 4   ALB         614 non-null    float64\n",
      " 5   ALP         597 non-null    float64\n",
      " 6   ALT         614 non-null    float64\n",
      " 7   AST         615 non-null    float64\n",
      " 8   BIL         615 non-null    float64\n",
      " 9   CHE         615 non-null    float64\n",
      " 10  CHOL        605 non-null    float64\n",
      " 11  CREA        615 non-null    float64\n",
      " 12  GGT         615 non-null    float64\n",
      " 13  PROT        614 non-null    float64\n",
      "dtypes: float64(10), int64(2), object(2)\n",
      "memory usage: 67.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ed1752",
   "metadata": {},
   "source": [
    "# To-Do  Start investigating the data types and correcting that \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd853f0",
   "metadata": {},
   "source": [
    "* As we see, we have 2 categorical attributes: Category and Sex\n",
    "* Then, we will check how many categories there are in each attribute, that will help us to convert them into numerical values using dictionnary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da61600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['m', 'f'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf857526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis',\n",
       "       '2=Fibrosis', '3=Cirrhosis'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f653b7d",
   "metadata": {},
   "source": [
    "* Here, we will use dictionnary to define new features with numerical values and then we will replace them in our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "112ff3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_Sex ={\"Sex\": {\"m\":0, \"f\": 1}}\n",
    "numerical_Category={\"0=Blood Donor\": 1,\"0s=suspect Blood Donor\": 1, \"1=Hepatitis\":2,\"2=Fibrosis\":3, \"3=Cirrhosis\":4  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6487676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.replace(numerical_Sex)\n",
    "data=data.replace(numerical_Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72192535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66ebf2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f98bda",
   "metadata": {},
   "source": [
    "* Now, we are sure that we have only numerical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d1a20",
   "metadata": {},
   "source": [
    "> Data types are all numeric Now ! Next we need to deal with missing values for the feature columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0524721b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#To-Do list all the columns that contain missing values along with their counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do Start providing solutions for each column that has missing data \n",
    "# Treat each case seperately \n",
    "# Hint : no data row should be deleted \n",
    "# Provide evidence that you filled those missing values after each step "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730b0fb",
   "metadata": {},
   "source": [
    "Detect missing values:\n",
    "df. isna(). sum() returns the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7c17db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     0\n",
       "Category       0\n",
       "Age            0\n",
       "Sex            0\n",
       "ALB            1\n",
       "ALP           18\n",
       "ALT            1\n",
       "AST            0\n",
       "BIL            0\n",
       "CHE            0\n",
       "CHOL          10\n",
       "CREA           0\n",
       "GGT            0\n",
       "PROT           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886ccc48",
   "metadata": {},
   "source": [
    "So features having missing values are: ALB, ALP, ALT, CHOL, PROT\n",
    "\n",
    "\n",
    "\n",
    "Since, no data row should be deleted, we will use Imputation: mean (numerical data) else mediand and  mode \n",
    "    df[\"Name\"].filln(df[\"Name\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "027c9fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"ALB\"].fillna(data[\"ALB\"].mean(), inplace=True)\n",
    "# we will verify if there is no missing value in this attribute \n",
    "data.ALB.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b10a5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"ALP\"].fillna(data[\"ALP\"].mean(), inplace=True)\n",
    "# we will verify if there is no missing value in this attribute \n",
    "data.ALP.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc38266f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"CHOL\"].fillna(data[\"CHOL\"].mean(), inplace=True)\n",
    "# we will verify if there is no missing value in this attribute \n",
    "data.CHOL.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8d29365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"PROT\"].fillna(data[\"PROT\"].mean(), inplace=True)\n",
    "# we will verify if there is no missing value in this attribute \n",
    "data.PROT.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb1158",
   "metadata": {},
   "source": [
    "> We have no more missing data\n",
    "As an optional thing we can also rename the first column as 'index' or \"ID\" instead of Unnamed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd552319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Category', 'Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST',\n",
       "       'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "255cb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Unnamed: 0': \"ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f63998c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Category', 'Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL',\n",
       "       'CHE', 'CHOL', 'CREA', 'GGT', 'PROT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f2464",
   "metadata": {},
   "source": [
    "### 6. Save the clean dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b7d623f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Saved/DataCleaning.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13096/3720223838.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Don't forget to drop the index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Saved/DataCleaning.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Saved/DataCleaning.csv'"
     ]
    }
   ],
   "source": [
    "# Don't forget to drop the index \n",
    "data.to_csv('Saved/DataCleaning.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9af0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
